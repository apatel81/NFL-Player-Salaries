---
title: "NFL Salary WR Data 2020"
output: html_notebook
---

###Reading the Data###
```{r}

library(tidyverse)
library(cluster)    
library(factoextra) 
library(randomForest)
require(caTools)
library(ggfortify)
library(ROCR)

wr <- read.csv("/Users/ajaypatel21/Personal Projects/NFL Notebooks/NFL_salary_WR_data2020.csv")
wr
```

###Cleaning Data###
```{r}
wr <- wr %>%
  filter(Receptions >= 9) %>%
  arrange(Receptions)

wr$Average.Guranteed.Per.Year <- str_replace(wr$Average.Guranteed.Per.Year, "\\$", "")
wr$Average.Guranteed.Per.Year <- str_replace_all(wr$Average.Guranteed.Per.Year, ",", "")
wr$Average.Guranteed.Per.Year <- as.numeric(wr$Average.Guranteed.Per.Year)

wr$Average.Per.Year <- str_replace(wr$Average.Per.Year, "\\$", "")
wr$Average.Per.Year <- str_replace_all(wr$Average.Per.Year, ",", "")
wr$Average.Per.Year <- as.numeric(wr$Average.Per.Year)

wr$Total.Guranteed <- str_replace(wr$Total.Guranteed, "\\$", "")
wr$Total.Guranteed <- str_replace_all(wr$Total.Guranteed, ",", "")
wr$Total.Guranteed <- as.numeric(wr$Total.Guranteed)

wr$Total.Value <- str_replace(wr$Total.Value, "\\$", "")
wr$Total.Value <- str_replace_all(wr$Total.Value, ",", "")
wr$Total.Value <- as.numeric(wr$Total.Value)

wr$Percent.Guranteed <- str_replace(wr$Percent.Guranteed, "%", "")
wr$Percent.Guranteed <- as.numeric(wr$Percent.Guranteed)
```


##KMeans Clustering (5 Clusters) - All Numeric Variables & PCA###
```{r}
# Extracting the numeric columns from the dataset
nums <- unlist(lapply(wr, is.numeric))
numeric_wr <- wr[ , nums]
numeric_wr$rowname <- wr$Name

numeric_wr <- numeric_wr %>%
  select(-Average.Guranteed.Per.Year, -Average.Per.Year, -Percent.Guranteed, -Total.Guranteed, -Total.Value)

# Setting the index of each row to the team name
numeric_wr <- column_to_rownames(numeric_wr)

# Fitting a KMeans model with 5 centroids
k <- kmeans(numeric_wr, centers = 5, nstart = 20)

# Plotting code
autoplot(prcomp(numeric_wr), data = wr, colour = 'Team_x', label = TRUE, label.size = 3) + ggtitle("WRs and Respective Teams")
autoplot(k, data = numeric_wr, label = TRUE, label.size = 3) + ggtitle("WRs and Assigned Cluster")

# Dendrogram Plot
hc <- agnes(numeric_wr, method = "ward")
pltree(hc, cex = 0.6, hang = -1, main = "Dendrogram of Players") 
rect.hclust(hc, k = 5, border = 2:5)
```

```{r}
# Adding assigned cluster to original dataframe
wr$cluster <- as.factor(k$cluster)

# Plotting code for Team_x Distribution by Cluster
ggplot(wr, aes(x = Total.Value, y = Yards, color = cluster)) + 
  geom_point() + geom_text(label = wr$Name) + theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(wr, aes(x = Total.Value, y = TDs, color = cluster)) + 
  geom_point() + geom_text(label = wr$Name) + theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(wr, aes(x = Total.Value, y = Total.Guranteed, color = cluster)) + 
  geom_point() + geom_text(label = wr$Name) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


MODEL 1: INITIAL MODEL 


Create initial model with all variables and calculate values
```{r data exploration}
library(recipes)
library(car)
library(broom)
library(nortest)
library(olsrr)

# MODEL 1

wr1 <- na.omit(wr) # Remove NAs
rownames(wr1) <- wr1$Name
model1 <- lm(Average.Per.Year ~ Forty.Plus  + Fumbles + TDs  + Yards.Per.Catch + 
             Yards.Per.Game, data=wr1) # Make model
del_resids <- rstudent(model1) # Calculate deleted residuals
leverages <- hatvalues(model1) # Calculate leverages
influences <- cooks.distance(model1) # Calculate cook's distances
```

Find Outliers, High Leverage Points, and Highly Influential Points of initial model with all variables
```{r extreme points}

# MODEL 1

wr1 <- wr1 %>% # Add residuals, leverages, and influences as columns in the data frame so we can access names
  mutate(del_resid = del_resids, 
         leverage = leverages,
         influences = influences)

alpha <- 0.05 # Set significance level
p <- length(coef(model1)) # number of parameters
n <- dim(wr1)[1] # number of observations

outliers <- wr1 %>% # Find names of extreme outlier colleges
  filter(abs(del_resid) > 3) %>%
  pull(Name)

high_leverages <- wr1 %>% # Find names of high leverage colleges
  filter(leverage > (3 * p) / n) %>%
  pull(Name)

influence_crit <- qf(0.50, p, n - p) # Find critical value for high influence
influential <- wr1 %>% # Find names of highly influential points
  filter(influences > influence_crit) %>%
  pull(Name)

outliers <- as.vector(outliers)                         #\
high_leverages <- as.vector(high_leverages)             # | Convert names of colleges to vectors
influential <- as.vector(influential)                   #/ 


paste("Number of outlier wrs:", length(outliers))
paste("They are:")
outliers
paste("")
paste("Number of high leverage wrs:", length(high_leverages))
paste("They are:")
high_leverages
paste("")
paste("Number of influential wrs:", length(influential))
```

Create Residual Plots of initial model with all variables:
```{r residual plots}

# MODEL 1

# Residual Plots for original model with all variables, no transformations
residualPlots(model1, type="rstudent", pch=20, ask=FALSE, test=FALSE, layout=c(3,3))
```

Create Normal Probability Plot and test normality of initial model with all variables: 
```{r test normality}

# MODEL 1

sf.test(del_resids) # Goodness-of-fit test for normality of residuals

ols_vif_tol(model1) %>% select(Variables, VIF) #Calculate VIFs

qqnorm(del_resids, # Plot points of normal probability plot
       ylab="Deleted Residuals",
       xlab="Normal Scores",
       main="Normal Probability Plot of Residuals",
       pch=20)
qqline(del_resids) # Add line
```


MODEL 2

Attempt to fix VIF of initial model with all variables and check constant variance, linearity, and normality:
```{r fixing VIF}

# MODEL 2 - VIFS ALL LOOK GOOD

# wr2 <- wr1 %>% # Create new variables to reduce multicollinearity
#   mutate(Twenty.Plus.Ratio = Attempts.Per.Game/(Forty.Plus + Twenty.Plus + 1)) #Attempts Per Game until Twenty + Yard Run
# 
# # wr2[is.na(wr2)] <- 0
# # 
# # wr2$TDs.Per.Sack[is.infinite(wr2$TDs.Per.Sack)] <- 0
# #          
# # Model with VIF-fixing transformed variables (removed Accepted, FTUG, Enrolled. Kept Apps)
# model2 <- lm(Average.Per.Year ~ Average.Per.Carry + Fumbles + TDs + 
#              Twenty.Plus.Ratio, data=wr2)
# 
# model2_resids <- rstudent(model2)
# 
# qqnorm(model2_resids, # Plot points of normal probability plot for best VIF-fixed model
#        ylab="Deleted Residuals",
#        xlab="Normal Scores",
#        main="Normal Probability Plot of Residuals",
#        pch=20)
# qqline(model2_resids) # Add line
# 
# ols_vif_tol(model2) %>% select(Variables, VIF) #Calculate VIFs
# 
# #Residual plots for this model with new variables
# residualPlots(model2, type="rstudent", pch=20, ask=FALSE, test=FALSE, layout=c(3,3))
```

```{r}
ggplot(wr1, aes(x=1/sqrt(Average.Per.Year))) + geom_histogram()
```


```{r transform data to fix unequal variances}

# MODEL 3
# wr3 <- wr2
wr3 <- wr1
wr3[, "Average.Per.Year"] <- sapply(wr3[, "Average.Per.Year"], function(x) ifelse(x == 0, 1, x))

wr3 <- wr3 %>%
  mutate(sqrt.Average.Per.Year = sqrt(Average.Per.Year))

model3 <- lm(sqrt.Average.Per.Year ~ Forty.Plus  + Fumbles + TDs  + Yards.Per.Catch + 
             Yards.Per.Game, data=wr3)
model3_resids <- rstudent(model3)
```

Residual Plots and Normal Probability plot for squared Gradrate:
```{r transformed resids squared}

# MODEL 3

#Residual plots for this model with y squared
residualPlots(model3, type="rstudent", pch=20, ask=FALSE, test=FALSE, layout=c(3,3))

qqnorm(model3_resids, # Plot points of normal probability plot for model with squared y
       ylab="Deleted Residuals",
       xlab="Normal Scores",
       main="Normal Probability Plot of Residuals",
       pch=20)
qqline(model3_resids) # Add line
del_resids3 <- rstudent(model3) # Calculate deleted residuals
sf.test(del_resids3) # Shapiro Wilks
ols_vif_tol(model3) %>% select(Variables, VIF) #Calculate VIFs
```
```{r}

# THIS LED TO ESSENTIALLY PERFECT FIT OF THE DATA

# wr3[, c("TDs", "Yards.Per.Game")] <- sapply(wr3[, "Average.Per.Year"], function(x) ifelse(x == 0, 1, x))
# 
# model3 <- lm(sqrt.Average.Per.Year ~ Forty.Plus  + Fumbles + sqrt(TDs)  + Yards.Per.Catch + 
#              sqrt(Yards.Per.Game), data=wr3)
# model3_resids <- rstudent(model3)
# 
# #Residual plots for this model with y squared
# residualPlots(model3, type="rstudent", pch=20, ask=FALSE, test=FALSE, layout=c(3,3))
# 
# qqnorm(model3_resids, # Plot points of normal probability plot for model with squared y
#        ylab="Deleted Residuals",
#        xlab="Normal Scores",
#        main="Normal Probability Plot of Residuals",
#        pch=20)
# qqline(model3_resids) # Add line
# del_resids3 <- rstudent(model3) # Calculate deleted residuals
# sf.test(del_resids3) # Shapiro Wilks
# ols_vif_tol(model3) %>% select(Variables, VIF) #Calculate VIFs
```


```{r centering predictor variables}

# MODEL 4

# Center all predictor variables
wr4 <- wr3 %>%
  mutate(c.Forty.Plus = scale(Forty.Plus, scale=FALSE),
         c.Fumbles = scale(Fumbles, scale=FALSE),
         c.TDs = scale(TDs, scale=FALSE),
         c.Yards.Per.Catch = scale(Yards.Per.Catch, scale=FALSE),
         c.Yards.Per.Game = scale(Yards.Per.Game, scale=FALSE))
# wr4 <- wr3 %>%
#   mutate(c.Forty.Plus = scale(Forty.Plus, scale=FALSE),
#          c.Fumbles = scale(Fumbles, scale=FALSE),
#          c.TDs = scale(sqrt(TDs), scale=FALSE),
#          c.Yards.Per.Catch = scale(Yards.Per.Catch, scale=FALSE),
#          c.Yards.Per.Game = scale(sqrt(Yards.Per.Game), scale=FALSE))

# squared.Total.Value ~ Average.Per.Carry + Fumbles + TDs + Attempts.Per.Game + 
#              Twenty.Plus.Ratio

# Model with all centered predictor variables
model4 <- lm(sqrt.Average.Per.Year ~ c.Forty.Plus + c.Fumbles + c.TDs + 
               c.Yards.Per.Catch + c.Yards.Per.Game, data=wr4)
centered_resids <- rstudent(model4)


#MODEL 4
#Residual plots for this model with y and all centered variables
residualPlots(model4, type="rstudent", pch=20, ask=FALSE, test=FALSE, layout=c(3,3))

qqnorm(centered_resids, # Plot points of normal probability plot for model with y and centered variables
       ylab="Deleted Residuals",
       xlab="Normal Scores",
       main="Normal Probability Plot of Residuals",
       pch=20)
qqline(centered_resids) # Add line

```


MODEL 5


Finding best model according to best subsets algorithm:
```{r best subsets model}

# MODEL 5 - FINAL MODEL 

subsets <- ols_step_all_possible(model4) # Calculate all possible subsets of predictors
# plot(subsets) # Plot scores
best_sub <- data.frame( # Get indices of models that have best R2-adjusted, Cp, and BIC
 Adj.R2 = which.max(subsets$adjr),
 CP = which.min(subsets$cp),
 BIC = which.min(subsets$sbc)
)
best_sub
# Model that minimizes Cp:
subsets[best_sub$CP, ]

subsets

# NOT USING BEST SUBSET MODEL - INSTEAD USING ALL 5 PREDICTORS BECAUSE 

best_sub_model <- lm(sqrt.Average.Per.Year ~ c.Forty.Plus + c.Fumbles + c.Yards.Per.Catch +
                       c.Yards.Per.Game, data=wr4)

best_sub_resids <- best_sub_model$residuals
  # rstudent(best_sub_model) # Deleted residuals of best subset model
best_sub_hats <- hatvalues(best_sub_model) # Leverages of best subset model
best_sub_cooks <- cooks.distance(best_sub_model) # Cooks's distances of best subset model

residualPlots(best_sub_model, type="rstudent", pch=20, ask=FALSE, test=FALSE) # Plot residual plots of best subset model

qqnorm(best_sub_resids, # Plot points of normal probability plot for best subset model
       ylab="Deleted Residuals",
       xlab="Normal Scores",
       main="Normal Probability Plot of Residuals",
       pch=20)
qqline(best_sub_resids) # Add line

sf.test(best_sub_resids) # Goodness-of-fit test

summary(best_sub_model) # Summary of model
```

Finding extreme points of best subset model:
```{r finding extreme points for best subset model}

# MODEL 6 - FINAL MODEL

wr5 <- data.frame(Name = wr4$Name,
                  del_resid = best_sub_resids,
                  leverage = best_sub_hats,
                  influence = best_sub_cooks)


p2 <- length(coef(best_sub_model)) # number of parameters
n2 <- dim(wr5)[1] # number of observations


best_sub_outliers <- as.vector(wr5 %>%
  filter(abs(del_resid) > 3) %>%
  pull(Name))

best_sub_high_leverages <- as.vector(wr5 %>%
  filter(leverage > (3 * p2) / n2) %>%
  pull(Name))

best_sub_influence_crit <- qf(0.50, p2, n2 - p2)

best_sub_influential <- as.vector(wr5 %>%
  filter(influence > best_sub_influence_crit) %>%
  pull(Name))


paste("Number of outlier wrs:", length(best_sub_outliers))

paste("Number of high leverage wrs:", length(best_sub_high_leverages))

paste("Number of influential wrs:", length(best_sub_influential))
```

VIFs of best subsets model:
```{r check VIFs of best subsets model}

# MODEL 6 - FINAL MODEL 

ols_vif_tol(best_sub_model) %>% select(Variables, VIF)
```


```{r test reduced vs full}

# MODEL 6 - FINAL MODEL

best_sub_model_small <- lm(sqrt.Average.Per.Year ~ c.Fumbles + c.TDs + c.Yards.Per.Catch, data=wr4)

model1_mod <- lm(sqrt.Average.Per.Year ~ Forty.Plus  + Fumbles + TDs  + Yards.Per.Catch + 
             Yards.Per.Game, data=wr4)

anova(best_sub_model_small, model1_mod)
```


```{r}
(best_sub_model$fitted.values)^2
```

```{r}
wr4$Prediction <- (best_sub_model$fitted.values)^2

wr4$color[wr4$Prediction <= wr4$Average.Per.Year] = "Annual Salary >= Predicted"
wr4$color[wr4$Prediction >= wr4$Average.Per.Year] = "Annual Salary < Predicted"

library(scales)
ggplot(wr4, aes(x=Prediction, y=Average.Per.Year, label=Name, colour=color)) + 
  geom_point() + 
  # geom_abline() + 
  # geom_smooth(method = "lm", se=F, colour="black") +
  geom_text() + 
  scale_x_continuous(labels = comma) + 
  scale_y_continuous(labels = comma) + 
  geom_hline(yintercept = mean(wr4$Average.Per.Year), linetype="dotted", color="#F8766D", size=1.0, show.legend=T) +
  geom_vline(xintercept = mean(wr4$Prediction), linetype="dotted", color = "#00BFC4", size=1.0) +
  ggtitle("WR Predicted Value vs Annual Contract")
```


```{r}
wr4 %>%
  select("Name", "Average.Per.Year", "Prediction") %>%
  mutate(Residual = Average.Per.Year - Prediction) %>%
  arrange(Residual) %>%
  filter(abs(Residual) >= 2000000)

```



